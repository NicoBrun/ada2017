{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing pipeline for 'meta_amazon_instant_video.json' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changelog : \n",
    "- v2 : removed model, added artist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='royalblue' size=3>\n",
    "<b>\n",
    "\n",
    "Parameters for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set which file to open and where\n",
    "datapath = '../DATA/'\n",
    "df_name = \"meta_Digital_Music\"\n",
    "\n",
    "## Specify which features we keep from the original table and which features \n",
    "## we add from the API queries\n",
    "features = ['asin', 'categories', 'title', 'salesRank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_add = ['actors', 'artist', 'authors', 'creators', 'directors']\n",
    "\n",
    "##  Change here which fields will be extracted from the amazon product\n",
    "##\n",
    "def set_df_cell_from_product(amazonProduct, rowNumber, fieldName1, fieldName2) :\n",
    "    if (amazonProduct is not None) : \n",
    "        amazon_products_df.set_value(rowNumber, \"actors\",\n",
    "                                     amazonProduct.actors)\n",
    "        amazon_products_df.set_value(rowNumber, \"directors\",\n",
    "                                     amazonProduct.directors)\n",
    "        amazon_products_df.set_value(rowNumber, \"creators\", \n",
    "                                     amazonProduct.creators)\n",
    "        amazon_products_df.set_value(rowNumber, \"authors\", \n",
    "                                     amazonProduct.authors)\n",
    "        #amazon_products_df.set_value(rowNumber, \"model\",    # The model field is always empty \n",
    "        #                             amazonProduct.model)\n",
    "        amazon_products_df.set_value(rowNumber, \"artist\",    # Added artist field by editing the API\n",
    "                                     amazonProduct.artist)\n",
    "\n",
    "        \n",
    "## Some less important parameters\n",
    "##\n",
    "        \n",
    "# version number to know which file was generated by which version of the notebook\n",
    "version=2\n",
    "# How frequently should we save our data to file\n",
    "data_save_freq = 7000\n",
    "# How many network errors we accept before we give up\n",
    "network_errors_limit = 8\n",
    "# stuff\n",
    "json_name = df_name+'.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#essential imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Sleep\n",
    "import time\n",
    "\n",
    "# Strict JSON conversion\n",
    "import json \n",
    "import gzip \n",
    "\n",
    "# Progress display\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "\n",
    "# Amazon API querying\n",
    "from amazon.api import AmazonAPI\n",
    "from amazon.api import AmazonProduct\n",
    "from amazon.api import AsinNotFound\n",
    "\n",
    "from urllib.request import HTTPError\n",
    "from socket import gaierror\n",
    "from urllib.request import URLError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='royalblue' size=3>\n",
    "<b>\n",
    "\n",
    "Open metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>imUrl</th>\n",
       "      <th>related</th>\n",
       "      <th>salesRank</th>\n",
       "      <th>categories</th>\n",
       "      <th>description</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5555991584</td>\n",
       "      <td>Memory of Trees</td>\n",
       "      <td>9.49</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/51b5WDjd...</td>\n",
       "      <td>{'also_bought': ['B000002LRT', 'B000002LRR', '...</td>\n",
       "      <td>{'Music': 939190}</td>\n",
       "      <td>[[CDs &amp; Vinyl, New Age, Celtic New Age], [CDs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6308051551</td>\n",
       "      <td>Don't Drink His Blood</td>\n",
       "      <td>8.91</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/31LT2n7Q...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Digital Music, Alternative Rock, Indie &amp; Lo-...</td>\n",
       "      <td>NEW Combo BLUWAVS CD and FLAC FILE</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7901622466</td>\n",
       "      <td>On Fire</td>\n",
       "      <td>11.33</td>\n",
       "      <td>http://ecx.images-amazon.com/images/I/21W29WZw...</td>\n",
       "      <td>{'also_bought': ['B00000282A', 'B0084O8O9S', '...</td>\n",
       "      <td>{'Music': 58799}</td>\n",
       "      <td>[[CDs &amp; Vinyl, Christian, Rock &amp; Alternative],...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                  title  price  \\\n",
       "0  5555991584        Memory of Trees   9.49   \n",
       "1  6308051551  Don't Drink His Blood   8.91   \n",
       "2  7901622466                On Fire  11.33   \n",
       "\n",
       "                                               imUrl  \\\n",
       "0  http://ecx.images-amazon.com/images/I/51b5WDjd...   \n",
       "1  http://ecx.images-amazon.com/images/I/31LT2n7Q...   \n",
       "2  http://ecx.images-amazon.com/images/I/21W29WZw...   \n",
       "\n",
       "                                             related          salesRank  \\\n",
       "0  {'also_bought': ['B000002LRT', 'B000002LRR', '...  {'Music': 939190}   \n",
       "1                                                NaN                NaN   \n",
       "2  {'also_bought': ['B00000282A', 'B0084O8O9S', '...   {'Music': 58799}   \n",
       "\n",
       "                                          categories  \\\n",
       "0  [[CDs & Vinyl, New Age, Celtic New Age], [CDs ...   \n",
       "1  [[Digital Music, Alternative Rock, Indie & Lo-...   \n",
       "2  [[CDs & Vinyl, Christian, Rock & Alternative],...   \n",
       "\n",
       "                          description brand  \n",
       "0                                 NaN   NaN  \n",
       "1  NEW Combo BLUWAVS CD and FLAC FILE   NaN  \n",
       "2                                 NaN   NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load all ASINs we're going to query - use the metadata files\n",
    "## for this, as they contains each ASIN once and only once.\n",
    "##\n",
    "\n",
    "''' This function was provided on the amazon dataset's webpage\n",
    "    It loads a gzipped file directly into a dataframe\n",
    "'''\n",
    "def gz_to_dataframe(datapath, filename):\n",
    "    def parse(path): \n",
    "        g = gzip.open(path, 'rb') \n",
    "        for l in g: \n",
    "            yield eval(l) \n",
    "    def getDF(path): \n",
    "        i = 0 \n",
    "        df = {} \n",
    "        for d in parse(path): \n",
    "            df[i] = d \n",
    "            i += 1 \n",
    "        return pd.DataFrame.from_dict(df, orient='index') \n",
    "    return getDF(datapath+filename)\n",
    "    \n",
    "amazon_products_df = gz_to_dataframe(datapath, json_name)\n",
    "amazon_products_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>categories</th>\n",
       "      <th>title</th>\n",
       "      <th>salesRank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5555991584</td>\n",
       "      <td>[[CDs &amp; Vinyl, New Age, Celtic New Age], [CDs ...</td>\n",
       "      <td>Memory of Trees</td>\n",
       "      <td>{'Music': 939190}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6308051551</td>\n",
       "      <td>[[Digital Music, Alternative Rock, Indie &amp; Lo-...</td>\n",
       "      <td>Don't Drink His Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7901622466</td>\n",
       "      <td>[[CDs &amp; Vinyl, Christian, Rock &amp; Alternative],...</td>\n",
       "      <td>On Fire</td>\n",
       "      <td>{'Music': 58799}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                                         categories  \\\n",
       "0  5555991584  [[CDs & Vinyl, New Age, Celtic New Age], [CDs ...   \n",
       "1  6308051551  [[Digital Music, Alternative Rock, Indie & Lo-...   \n",
       "2  7901622466  [[CDs & Vinyl, Christian, Rock & Alternative],...   \n",
       "\n",
       "                   title          salesRank  \n",
       "0        Memory of Trees  {'Music': 939190}  \n",
       "1  Don't Drink His Blood                NaN  \n",
       "2                On Fire   {'Music': 58799}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_products_df = amazon_products_df[features]\n",
    "amazon_products_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='royalblue' size=3>\n",
    "<b>\n",
    "\n",
    "Prepare for amazon api usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sign in with amazon API \n",
    "##\n",
    "\n",
    "def get_amazon_interface():\n",
    "    f = open(\"api_creds\")\n",
    "    ar = f.read().split(\"\\n\")\n",
    "    return AmazonAPI(ar[0], ar[1], ar[2])\n",
    "    return ar[0], ar[1], ar[2]\n",
    "\n",
    "amazon = get_amazon_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Here, we define some API query helpers\n",
    "##\n",
    "\n",
    "''' Product lookup with API, asin can be a string ('one by one' lookup)\n",
    "    or a list of strings ('bulk lookup').\n",
    "    bulk lookup provides better performance\n",
    "'''\n",
    "def get_prod(asin) : \n",
    "    if not isinstance(asin, str): \n",
    "        acc_str = str(asin[0])\n",
    "        for e in asin : \n",
    "            acc_str += ','+str(e)\n",
    "        return amazon.lookup(ItemId=acc_str)\n",
    "    else :\n",
    "        return amazon.lookup(ItemId=asin)\n",
    "    \n",
    "''' Splits the interval [start-end] into bulks of size bulksize\n",
    "'''    \n",
    "def gen_bulk_index(start, end, bulksize=10, includeEnd=False):\n",
    "    size = end - start + 1\n",
    "    if(includeEnd):\n",
    "        size+=1\n",
    "    if size==1 : \n",
    "       return [[start]]\n",
    "    bulks = [list(range(start+(i*bulksize), start + (i+1)*bulksize)) for i in range(0, int(size/bulksize))]\n",
    "    if includeEnd : \n",
    "        bulks.append(list(range(bulks[len(bulks)-1][bulksize-1], end+1)))\n",
    "    else : \n",
    "        bulks.append(list(range(bulks[len(bulks)-1][bulksize-1], end)))\n",
    "    return bulks    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Also, we have some functions to save the state of our data structure - in case we need to \n",
    "## to shutdown the computer and restart the query loop at a later time (not used here)\n",
    "##\n",
    "\n",
    "def save_progress(dataframe, nb_rows_processed):\n",
    "    clear_output()\n",
    "    print(\"SAVING PROGRESS - DONT STOP THE CELL\")\n",
    "    sys.stdout.flush()\n",
    "    time.sleep(3)\n",
    "    dataframe.to_csv(datapath+df_name+\"_temp.csv\", index=False, encoding='utf-8')\n",
    "    file = open(datapath+df_name+\"_progress\", \"w\")\n",
    "    file.write(str(nb_rows_processed))\n",
    "    time.sleep(2)\n",
    "    print(\"SAVE COMPLETED - WAIT FOR QUERY LOOP TO RESUME\")    \n",
    "    time.sleep(5)\n",
    "\n",
    "    \n",
    "def load_progress():\n",
    "    dataframe = pd.read_csv(datapath+df_name+\"_temp(v\"+str(version)+\").csv\")\n",
    "    file = open(datapath+df_name+\"_progress\", \"r\")\n",
    "    nb_rows_processed = file.readline()\n",
    "    return dataframe, int(nb_rows_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='royalblue' size=3>\n",
    "<b>\n",
    "\n",
    "Bulk lookups parameters and loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last item looked up :  0   -  time :  11:23:24 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Parameters & initialization for bulk item lookup\n",
    "##\n",
    "\n",
    "bulksize = 10\n",
    "\n",
    "# Change this to restore progress from file\n",
    "fresh_run = True\n",
    "\n",
    "if fresh_run : \n",
    "    # used to restart from where we were in case of unexepected network error\n",
    "    lastItemLookedUp = 0\n",
    "    for col in columns_to_add : \n",
    "        amazon_products_df[col] = pd.Series(dtype=str)\n",
    "else : \n",
    "    amazon_products_df, lastItemLookedUp = load_progress()\n",
    "    \n",
    "print(\"last item looked up : \", lastItemLookedUp,  \"  -  time : \",time.strftime(\"%H:%M:%S\"), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0 % completed ( 150  rows)   -  time :  11:24:08\n",
      "         Last Item Looked up :  149  /  279899\n",
      "         HTTPErrors :  0\n",
      "         gaierrors :  0\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ab7bcc022765>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# limit query frequency to avoid 503 errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mloop_complete\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Querying loop\n",
    "##\n",
    "\n",
    "ref_for_progress = lastItemLookedUp\n",
    "lastErrorMet=lastItemLookedUp\n",
    "loop_complete = False\n",
    "caught_httperrors=0\n",
    "caught_gaierrors=0\n",
    "errors_counter=0\n",
    "\n",
    "def printprogress() :\n",
    "    clear_output()\n",
    "    print(\"    \",int(100 * (bulk[0]+1) / amazon_products_df.shape[0]), \"% completed (\",bulk[0], \" rows)\", \"  -  time : \",time.strftime(\"%H:%M:%S\"))\n",
    "    print(\"         Last Item Looked up : \", lastItemLookedUp, \" / \", amazon_products_df.shape[0])\n",
    "    print(\"         HTTPErrors : \", caught_httperrors)\n",
    "    print(\"         gaierrors : \", caught_gaierrors)\n",
    "    print(\"\\n\\n\\n\")\n",
    "\n",
    "while not loop_complete : \n",
    "    try : \n",
    "        \n",
    "        for bulk in gen_bulk_index(ref_for_progress, amazon_products_df.shape[0], bulksize=bulksize) : \n",
    "            # update progess every 100 items\n",
    "            if ((bulk[0]-(ref_for_progress)) % 50 == 0) : \n",
    "                printprogress()\n",
    "\n",
    "            # get asins for the bulk and fetch the matching AmazonProducts\n",
    "            asins = amazon_products_df['asin'][bulk].tolist()\n",
    "            noAsinFound = False\n",
    "            try : \n",
    "                prods = get_prod(asins)\n",
    "            except AsinNotFound : \n",
    "                noAsinFound = True\n",
    "                \n",
    "            # if query was successful, reset error counter\n",
    "            errors_counter = 0;\n",
    "            \n",
    "            # Then, process each product to add necessary informations in the dataframe\n",
    "            if noAsinFound : \n",
    "                # Skip this bulk and reset the flag\n",
    "                print(\"No Asin Found for bulk : \", bulk)\n",
    "            elif (type(prods) is list) and (len(prods) == bulksize) :              \n",
    "                # Case : we found exactly one result per ASIN\n",
    "                #        process by bulk\n",
    "                    for i, prod in enumerate(prods) : \n",
    "                        set_df_cell_from_product(prod, bulk[i], \"actors\", \"directors\")\n",
    "            elif (type(prods) is list) or (type(prods) is AmazonProduct) :  \n",
    "                # Case : we obtained a list of AmazonProducts or a single AmazonProduct\n",
    "                #        fallback to 1-by-1 querying\n",
    "                for n in bulk :               \n",
    "                    asin = amazon_products_df['asin'][n]\n",
    "                    try : \n",
    "                        prod = get_prod(asin)\n",
    "                    except(AsinNotFound): \n",
    "                        prod = None\n",
    "                    set_df_cell_from_product(prod, n, \"actors\", \"directors\")\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "            # Save progress\n",
    "            lastItemLookedUp = bulk[len(bulk)-1]\n",
    "            \n",
    "            # Save data to file according to specified frequency\n",
    "            if ((bulk[0]-(ref_for_progress)) % data_save_freq == 0) and (bulk[0]-(ref_for_progress))!=0 : \n",
    "                save_progress(amazon_products_df, lastItemLookedUp)\n",
    "            \n",
    "            # limit query frequency to avoid 503 errors\n",
    "            time.sleep(2)\n",
    "            \n",
    "        loop_complete = True\n",
    "        \n",
    "\n",
    "    except HTTPError :\n",
    "        errors_counter += 1\n",
    "        caught_httperrors += 1\n",
    "        # If we didn't make any progress, something must be wrong\n",
    "        if errors_counter > network_errors_limit : \n",
    "            print(\"HTTPError caught at original_lastItemLookedUp  -  breaking\")\n",
    "            break \n",
    "        # else retry\n",
    "        printprogress()\n",
    "        print(\"      httpError\")\n",
    "        ref_for_progress = lastItemLookedUp\n",
    "        lastErrorMet = lastItemLookedUp\n",
    "        \n",
    "    except(gaierror, URLError): \n",
    "        errors_counter += 1\n",
    "        caught_gaierrors += 1\n",
    "        if errors_counter > network_errors_limit : \n",
    "            print(\"gaierror/urlerror caught too many times  -  breaking\")\n",
    "            break \n",
    "        # else retry\n",
    "        printprogress()\n",
    "        print(\"      GAIError\")\n",
    "        ref_for_progress = lastItemLookedUp\n",
    "        lastErrorMet = lastItemLookedUp\n",
    "        \n",
    "     # recovery time in case of error\n",
    "    print(\"       recovery time\")\n",
    "    time.sleep(4)\n",
    "            \n",
    "        \n",
    "\n",
    "if(loop_complete):\n",
    "    clear_output()    \n",
    "    print(\"amazon query loop completed !\")\n",
    "    # save results\n",
    "    amazon_products_df.to_csv(datapath+df_name+\"_processed(v\"+str(version)+\").csv\")\n",
    "    print('Results saved to file !')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raise NotImplementedError(\"Fence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run this to manually save progress\n",
    "##\n",
    "save_progress()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
