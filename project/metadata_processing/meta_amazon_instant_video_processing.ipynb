{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing pipeline for 'meta_amazon_instant_video.json' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='royalblue' size=3>\n",
    "<b>\n",
    "\n",
    "Parameters for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Set which file to open and where\n",
    "datapath = '../DATA/'\n",
    "df_name = \"meta_Amazon_Instant_Video\"\n",
    "\n",
    "## Specify which features we keep from the original table and which features \n",
    "## we add from the API queries\n",
    "features = ['asin', 'categories']\n",
    "columns_to_add = ['actors', 'directors', 'creators', 'authors', \"model\"]\n",
    "\n",
    "##  Change here which fields will be extracted from the amazon product\n",
    "##\n",
    "def set_df_cell_from_product(amazonProduct, rowNumber, fieldName1, fieldName2) :\n",
    "    if (amazonProduct is not None) : \n",
    "        amazon_products_df.set_value(rowNumber, \"actors\",\n",
    "                                     amazonProduct.actors)\n",
    "        amazon_products_df.set_value(rowNumber, \"directors\",\n",
    "                                     amazonProduct.directors)\n",
    "        amazon_products_df.set_value(rowNumber, \"creators\", \n",
    "                                     amazonProduct.creators)\n",
    "        amazon_products_df.set_value(rowNumber, \"authors\", \n",
    "                                     amazonProduct.authors)\n",
    "        amazon_products_df.set_value(rowNumber, \"model\", \n",
    "                                     amazonProduct.model)\n",
    "        #amazon_products_df.set_value(rowNumber, \"artists\",    # There is definitely no \"artists\" field\n",
    "        #                             amazonProduct.artists)\n",
    "\n",
    "        \n",
    "## Some less important parameters\n",
    "##\n",
    "        \n",
    "# version number to know which file was generated by which version of the notebook\n",
    "version=1\n",
    "# How frequently should we save our data to file\n",
    "data_save_freq = 10000\n",
    "# How many network errors we accept before we give up\n",
    "network_errors_limit = 7\n",
    "# stuff\n",
    "json_name = df_name+'.json.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#essential imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Sleep\n",
    "import time\n",
    "\n",
    "# Strict JSON conversion\n",
    "import json \n",
    "import gzip \n",
    "\n",
    "# Progress display\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Amazon API querying\n",
    "from amazon.api import AmazonAPI\n",
    "from amazon.api import AsinNotFound\n",
    "\n",
    "from urllib.request import HTTPError\n",
    "from socket import gaierror\n",
    "from urllib.request import URLError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='royalblue' size=3>\n",
    "<b>\n",
    "\n",
    "Open metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>categories</th>\n",
       "      <th>price</th>\n",
       "      <th>related</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000GFDAUG</td>\n",
       "      <td>[[Amazon Instant Video]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000GIOPK2</td>\n",
       "      <td>[[Amazon Instant Video]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000GIPKWY</td>\n",
       "      <td>[[Amazon Instant Video]]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                categories  price related\n",
       "0  B000GFDAUG  [[Amazon Instant Video]]    NaN     NaN\n",
       "1  B000GIOPK2  [[Amazon Instant Video]]    NaN     NaN\n",
       "2  B000GIPKWY  [[Amazon Instant Video]]    NaN     NaN"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load all ASINs we're going to query - use the metadata files\n",
    "## for this, as they contains each ASIN once and only once.\n",
    "##\n",
    "\n",
    "''' This function was provided on the amazon dataset's webpage\n",
    "    It loads a gzipped file directly into a dataframe\n",
    "'''\n",
    "def gz_to_dataframe(datapath, filename):\n",
    "    def parse(path): \n",
    "        g = gzip.open(path, 'rb') \n",
    "        for l in g: \n",
    "            yield eval(l) \n",
    "    def getDF(path): \n",
    "        i = 0 \n",
    "        df = {} \n",
    "        for d in parse(path): \n",
    "            df[i] = d \n",
    "            i += 1 \n",
    "        return pd.DataFrame.from_dict(df, orient='index') \n",
    "    return getDF(datapath+filename)\n",
    "    \n",
    "amazon_products_df = gz_to_dataframe(datapath, json_name)\n",
    "amazon_products_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B000GFDAUG</td>\n",
       "      <td>[[Amazon Instant Video]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B000GIOPK2</td>\n",
       "      <td>[[Amazon Instant Video]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B000GIPKWY</td>\n",
       "      <td>[[Amazon Instant Video]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin                categories\n",
       "0  B000GFDAUG  [[Amazon Instant Video]]\n",
       "1  B000GIOPK2  [[Amazon Instant Video]]\n",
       "2  B000GIPKWY  [[Amazon Instant Video]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_products_df = amazon_products_df[features]\n",
    "amazon_products_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='royalblue' size=3>\n",
    "<b>\n",
    "\n",
    "Prepare for amazon api usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Sign in with amazon API \n",
    "##\n",
    "\n",
    "def get_amazon_interface():\n",
    "    f = open(\"api_creds\")\n",
    "    ar = f.read().split(\"\\n\")\n",
    "    return AmazonAPI(ar[0], ar[1], ar[2])\n",
    "    return ar[0], ar[1], ar[2]\n",
    "\n",
    "amazon = get_amazon_interface()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Here, we define some API query helpers\n",
    "##\n",
    "\n",
    "''' Product lookup with API, asin can be a string ('one by one' lookup)\n",
    "    or a list of strings ('bulk lookup').\n",
    "    bulk lookup provides better performance\n",
    "'''\n",
    "def get_prod(asin) : \n",
    "    if not isinstance(asin, str): \n",
    "        acc_str = str(asin[0])\n",
    "        for e in asin : \n",
    "            acc_str += ','+str(e)\n",
    "        return amazon.lookup(ItemId=acc_str)\n",
    "    else :\n",
    "        return amazon.lookup(ItemId=asin)\n",
    "    \n",
    "''' Splits the interval [start-end] into bulks of size bulksize\n",
    "'''    \n",
    "def gen_bulk_index(start, end, bulksize=10, includeEnd=False):\n",
    "    size = end - start + 1\n",
    "    bulks = [list(range(start+(i*bulksize), start + (i+1)*bulksize)) for i in range(0, int(size/bulksize))]\n",
    "    if includeEnd : \n",
    "        bulks.append(list(range(bulks[len(bulks)-1][bulksize-1], end+1)))\n",
    "    else : \n",
    "        bulks.append(list(range(bulks[len(bulks)-1][bulksize-1], end)))\n",
    "    return bulks    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Also, we have some functions to save the state of our data structure - in case we need to \n",
    "## to shutdown the computer and restart the query loop at a later time (not used here)\n",
    "##\n",
    "\n",
    "def save_progress(dataframe, nb_rows_processed):\n",
    "    dataframe.to_csv(datapath+df_name+\"_temp(v\"+str(version)+\").csv\", index=False)\n",
    "    file = open(datapath+df_name+\"_progress\", \"w\")\n",
    "    file.write(str(nb_rows_processed))\n",
    "\n",
    "    \n",
    "def load_progress():\n",
    "    dataframe = pd.read_csv(datapath+df_name+\"_temp(v\"+str(version)+\").csv\")\n",
    "    file = open(datapath+df_name+\"_progress\", \"r\")\n",
    "    nb_rows_processed = file.readline()\n",
    "    return dataframe, int(nb_rows_processed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='royalblue' size=3>\n",
    "<b>\n",
    "\n",
    "Bulk lookups parameters and loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last item looked up :  30626   -  time :  17:53:04 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Parameters & initialization for bulk item lookup\n",
    "##\n",
    "\n",
    "bulksize = 10\n",
    "\n",
    "# Change this to restore progress from file\n",
    "fresh_run = False\n",
    "\n",
    "if fresh_run : \n",
    "    # used to restart from where we were in case of unexepected network error\n",
    "    lastItemLookedUp = 0\n",
    "    for col in columns_to_add : \n",
    "        amazon_products_df[col] = pd.Series(dtype=str)\n",
    "else : \n",
    "    amazon_products_df, lastItemLookedUp = load_progress()\n",
    "    \n",
    "print(\"last item looked up : \", lastItemLookedUp,  \"  -  time : \",time.strftime(\"%H:%M:%S\"), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon query loop completed !\n"
     ]
    }
   ],
   "source": [
    "## Querying loop\n",
    "##\n",
    "\n",
    "ref_for_progress = lastItemLookedUp\n",
    "lastErrorMet=lastItemLookedUp\n",
    "loop_complete = False\n",
    "caught_httperrors=0\n",
    "caught_gaierrors=0\n",
    "errors_counter=0\n",
    "\n",
    "\n",
    "while not loop_complete : \n",
    "    try : \n",
    "        \n",
    "        for bulk in gen_bulk_index(ref_for_progress, amazon_products_df.shape[0], bulksize=bulksize) : \n",
    "            # update progess every 100 items\n",
    "            if ((bulk[0]-(ref_for_progress)) % 50 == 0) : \n",
    "                clear_output()\n",
    "                print(\"    \",int(100 * (bulk[0]+1) / amazon_products_df.shape[0]), \"% completed (\",bulk[0], \" rows)\", \"  -  time : \",time.strftime(\"%H:%M:%S\"))\n",
    "                print(\"         Last Item Looked up : \", lastItemLookedUp, \" / \", amazon_products_df.shape[0])\n",
    "                print(\"         HTTPErrors caught : \", caught_httperrors)\n",
    "                print(\"         gaierrors caught : \", caught_gaierrors)\n",
    "                print(\"\\n\")\n",
    "\n",
    "            # get asins for the bulk and fetch the matching AmazonProducts\n",
    "            asins = amazon_products_df['asin'][bulk].tolist()\n",
    "            noAsinFound = False\n",
    "            try : \n",
    "                prods = get_prod(asins)\n",
    "            except AsinNotFound : \n",
    "                noAsinFound = True\n",
    "                \n",
    "            # if query was successful, reset error counter\n",
    "            errors_counter = 0;\n",
    "            \n",
    "            # Then, process each product to add necessary informations in the dataframe\n",
    "            if noAsinFound : \n",
    "                # Skip this bulk and reset the flag\n",
    "                print(\"No Asin Found for bulk : \", bulk)\n",
    "            elif (type(prods) is list) and (len(prods) == bulksize) :              \n",
    "                # Case : we found exactly one result per ASIN\n",
    "                #        process by bulk\n",
    "                    for i, prod in enumerate(prods) : \n",
    "                        set_df_cell_from_product(prod, bulk[i], \"actors\", \"directors\")\n",
    "            elif (type(prods) is list) or (type(prods) is AmazonApi.AmazonProduct) :  \n",
    "                # Case : we obtained a list of AmazonProducts or a single AmazonProduct\n",
    "                #        fallback to 1-by-1 querying\n",
    "                for n in bulk :               \n",
    "                    asin = amazon_products_df['asin'][n]\n",
    "                    try : \n",
    "                        prod = get_prod(asin)\n",
    "                    except(AsinNotFound): \n",
    "                        prod = None\n",
    "                    set_df_cell_from_product(prod, n, \"actors\", \"directors\")\n",
    "                    time.sleep(0.5)\n",
    "\n",
    "            # Save progress\n",
    "            lastItemLookedUp = bulk[len(bulk)-1]\n",
    "            \n",
    "            # Save data to file according to specified frequency\n",
    "            if ((bulk[0]-(ref_for_progress)) % data_save_freq == 0) : \n",
    "                save_progress(amazon_products_df, lastItemLookedUp)\n",
    "            \n",
    "            # limit query frequency to avoid 503 errors\n",
    "            time.sleep(min(bulksize/25, 5))\n",
    "            \n",
    "        loop_complete = True\n",
    "        \n",
    "\n",
    "    except HTTPError :\n",
    "        errors_counter += 1\n",
    "        caught_httperrors += 1\n",
    "        # If we didn't make any progress, something must be wrong\n",
    "        if errors_counter > network_errors_limit : \n",
    "            print(\"HTTPError caught at original_lastItemLookedUp  -  breaking\")\n",
    "            break \n",
    "        # else retry\n",
    "        print(\"\\n\\nhttpError\\n\\n\")\n",
    "        ref_for_progress = lastItemLookedUp\n",
    "        lastErrorMet = lastItemLookedUp\n",
    "        \n",
    "    except(gaierror, URLError): \n",
    "        errors_counter += 1\n",
    "        caught_gaierrors += 1\n",
    "        if errors_counter > network_errors_limit : \n",
    "            print(\"gaierror/urlerror caught too many times  -  breaking\")\n",
    "            break \n",
    "        # else retry\n",
    "        print(\"\\n\\ngaierror/urlerror\\n\\n\")\n",
    "        ref_for_progress = lastItemLookedUp\n",
    "        lastErrorMet = lastItemLookedUp\n",
    "        \n",
    "\n",
    "if(loop_complete):\n",
    "    clear_output()    \n",
    "    print(\"amazon query loop completed !\")\n",
    "    # save results\n",
    "    amazon_products_df.to_csv(datapath+df_name+\"_processed(v\"+str(version)+\").csv\")\n",
    "    print('Results saved to file !')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Run this cell to manually save results\n",
    "##\n",
    "\n",
    "save_progress(amazon_products_df, lastItemLookedUp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>categories</th>\n",
       "      <th>actors</th>\n",
       "      <th>directors</th>\n",
       "      <th>creators</th>\n",
       "      <th>authors</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30643</th>\n",
       "      <td>B00LSWLQQQ</td>\n",
       "      <td>[['Amazon Instant Video']]</td>\n",
       "      <td>[Brian Godawa]</td>\n",
       "      <td>[Brian Godawa]</td>\n",
       "      <td>[(Brian Godawa, Writer), (Brian Godawa, Produc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30644</th>\n",
       "      <td>B00LTMJ29S</td>\n",
       "      <td>[['Amazon Instant Video']]</td>\n",
       "      <td>[Sean Astin, Currie Graham, Brando Eaton, Jill...</td>\n",
       "      <td>[Kaare Andrews]</td>\n",
       "      <td>[(Jake Wade Wall, Writer), (Evan Astrowsky, Pr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30645</th>\n",
       "      <td>B00LSWNB9Q</td>\n",
       "      <td>[['Amazon Instant Video']]</td>\n",
       "      <td>[Nick Airus, Sean Paul Lockhart, Kyle Blitch, ...</td>\n",
       "      <td>[James Townsend]</td>\n",
       "      <td>[(James Townsend, Writer)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30646</th>\n",
       "      <td>B00LU8ONBI</td>\n",
       "      <td>[['Amazon Instant Video']]</td>\n",
       "      <td>[LeAnn Rimes, Eddie Cibrian]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30647</th>\n",
       "      <td>B00LXQXLGU</td>\n",
       "      <td>[['Amazon Instant Video']]</td>\n",
       "      <td>[Amy Smart, Joshua Leonard, Christian Campbell...</td>\n",
       "      <td>[Russell Friedenberg]</td>\n",
       "      <td>[(Russell Friedenberg, Writer)]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             asin                  categories  \\\n",
       "30643  B00LSWLQQQ  [['Amazon Instant Video']]   \n",
       "30644  B00LTMJ29S  [['Amazon Instant Video']]   \n",
       "30645  B00LSWNB9Q  [['Amazon Instant Video']]   \n",
       "30646  B00LU8ONBI  [['Amazon Instant Video']]   \n",
       "30647  B00LXQXLGU  [['Amazon Instant Video']]   \n",
       "\n",
       "                                                  actors  \\\n",
       "30643                                     [Brian Godawa]   \n",
       "30644  [Sean Astin, Currie Graham, Brando Eaton, Jill...   \n",
       "30645  [Nick Airus, Sean Paul Lockhart, Kyle Blitch, ...   \n",
       "30646                       [LeAnn Rimes, Eddie Cibrian]   \n",
       "30647  [Amy Smart, Joshua Leonard, Christian Campbell...   \n",
       "\n",
       "                   directors  \\\n",
       "30643         [Brian Godawa]   \n",
       "30644        [Kaare Andrews]   \n",
       "30645       [James Townsend]   \n",
       "30646                     []   \n",
       "30647  [Russell Friedenberg]   \n",
       "\n",
       "                                                creators authors model  \n",
       "30643  [(Brian Godawa, Writer), (Brian Godawa, Produc...      []  None  \n",
       "30644  [(Jake Wade Wall, Writer), (Evan Astrowsky, Pr...      []  None  \n",
       "30645                         [(James Townsend, Writer)]      []  None  \n",
       "30646                                                 []      []  None  \n",
       "30647                    [(Russell Friedenberg, Writer)]      []  None  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_products_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
