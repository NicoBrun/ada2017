{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#essential imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "#scraping imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#plotting imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. TopUniversities.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.1.  Obtain the 200 top-ranking universities in www.topuniversities.com ([ranking 2018](https://www.topuniversities.com/university-rankings/world-university-rankings/2018)). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the [details page](https://www.topuniversities.com/universities/ecole-polytechnique-fédérale-de-lausanne-epfl).\n",
    "\n",
    "** Method **\n",
    "Using the postman plugin on google chrome, we found the json representing the list of the universities:\n",
    "\n",
    "https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt?_=1508252855868\n",
    "\n",
    "\n",
    "We want to scrap those data from the site:\n",
    "* name \n",
    "* rank\n",
    "* country\n",
    "* region \n",
    "* number of faculty members (international and total)\n",
    "* number of students (international and total)\n",
    "\n",
    "In the JSON we retrieved, there is already the **name**, **rank**, **country** and **region**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>nid</th>\n",
       "      <th>rank_display</th>\n",
       "      <th>region</th>\n",
       "      <th>score</th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>294850</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>Massachusetts Institute of Technology (MIT)</td>\n",
       "      <td>/universities/massachusetts-institute-technolo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States</td>\n",
       "      <td>297282</td>\n",
       "      <td>2</td>\n",
       "      <td>North America</td>\n",
       "      <td>98.7</td>\n",
       "      <td>5</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>/universities/stanford-university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>294270</td>\n",
       "      <td>3</td>\n",
       "      <td>North America</td>\n",
       "      <td>98.4</td>\n",
       "      <td>5</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>/universities/harvard-university</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>294562</td>\n",
       "      <td>4</td>\n",
       "      <td>North America</td>\n",
       "      <td>97.7</td>\n",
       "      <td>5</td>\n",
       "      <td>California Institute of Technology (Caltech)</td>\n",
       "      <td>/universities/california-institute-technology-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>294561</td>\n",
       "      <td>5</td>\n",
       "      <td>Europe</td>\n",
       "      <td>95.6</td>\n",
       "      <td>5</td>\n",
       "      <td>University of Cambridge</td>\n",
       "      <td>/universities/university-cambridge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country     nid rank_display         region score stars  \\\n",
       "0   United States  294850            1  North America   100     6   \n",
       "1   United States  297282            2  North America  98.7     5   \n",
       "2   United States  294270            3  North America  98.4     5   \n",
       "3   United States  294562            4  North America  97.7     5   \n",
       "4  United Kingdom  294561            5         Europe  95.6     5   \n",
       "\n",
       "                                          title  \\\n",
       "0   Massachusetts Institute of Technology (MIT)   \n",
       "1                           Stanford University   \n",
       "2                            Harvard University   \n",
       "3  California Institute of Technology (Caltech)   \n",
       "4                       University of Cambridge   \n",
       "\n",
       "                                                 url  \n",
       "0  /universities/massachusetts-institute-technolo...  \n",
       "1                  /universities/stanford-university  \n",
       "2                   /universities/harvard-university  \n",
       "3  /universities/california-institute-technology-...  \n",
       "4                 /universities/university-cambridge  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#json to dataframe using panda\n",
    "json_data = json.load(open('TopUniRanking.json'))\n",
    "df = json_normalize(json_data['data'])\n",
    "#the university are sorted by ranks, so we just need the 200 first indexes\n",
    "dfTopUni200 = df.head(200)\n",
    "#drop useless column information\n",
    "dfTopUni200 = dfTopUni200.drop([\"cc\",\"core_id\",\"logo\",\"guide\"],axis=1)\n",
    "dfTopUni200.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Method **\n",
    "\n",
    "We now have the general data for the 200 first universities. Then we need to scrap data on each unique page of each university to retrieve those 4 informations: \n",
    "* **number of total faculty members** \n",
    "* **number of international faculty members**\n",
    "* **number of total students** \n",
    "* **number of international students**\n",
    "\n",
    "The url of each university is contained in our previous dataFrame. And the link to the pages follow this scheme:  \n",
    " **https://www.topuniversities.com+*url*** \n",
    " \n",
    "Using developper tool in google chrome to inspect the html of the page, we found that the 4 datas we want are located inside unique html objects that have as class: **total faculty**, **inter faculty**, **total student** and **total inter**.\n",
    "So to find those datas we filter by class name the html page, then we retreive the specific associated information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Warning :** the next cell requiers internet to work as intended and it lasts around 2 minutes of computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-aca62b9fb1eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mfinalUrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.topuniversities.com\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinalUrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m#todo: scrap with beautifulSoup using the url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#merge data into the temp dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, markup, features, builder, parse_only, from_encoding, exclude_encodings, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mParserRejectedMarkup\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/bs4/__init__.py\u001b[0m in \u001b[0;36m_feed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0;31m# Close out any unfinished strings and close all the open tags.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/site-packages/bs4/builder/_htmlparser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTMLParseError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             warnings.warn(RuntimeWarning(\n",
      "\u001b[0;32m/usr/lib/python3.6/html/parser.py\u001b[0m in \u001b[0;36mfeed\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \"\"\"\n\u001b[1;32m    110\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrawdata\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoahead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/html/parser.py\u001b[0m in \u001b[0;36mgoahead\u001b[0;34m(self, end)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstarttagopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# < + letter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_starttag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"</\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_endtag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/html/parser.py\u001b[0m in \u001b[0;36mparse_starttag\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlasttag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mendpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrfind_tolerant\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "listUrl = dfTopUni200['url']\n",
    "#create a temporary dataframe\n",
    "index = range(200)\n",
    "columns = [\"nbr_faculty_members\",\"nbr_international_faculty_members\",\"nbr_total_students\",\"nbr_international_total_students\"]\n",
    "temp_df = pd.DataFrame(index=index,columns=columns)\n",
    "\n",
    "#helper function that filter the html file and return the int corresponding to the special string htmlClass\n",
    "#return NaN if the object doesn't exist\n",
    "def findNumberOf(soup,htmlClass):\n",
    "    filteredHtmlElements = soup.find_all('div', class_=htmlClass)\n",
    "    #case if a field information is not given\n",
    "    if(len(filteredHtmlElements)==0):\n",
    "        return np.nan\n",
    "    #find the integer value inside the html balise\n",
    "    t= filteredHtmlElements[0].find('div', class_='number').text\n",
    "    #clear the input then convert it into an integer\n",
    "    return int(t.replace('\\n', '').replace('\\r', '').replace(',', '').replace(' ',''))\n",
    "\n",
    "#retrieve the 4 informations needed from the url, for each university\n",
    "for i,url in enumerate(listUrl):\n",
    "    finalUrl = \"https://www.topuniversities.com\"+url\n",
    "    r = requests.get(finalUrl)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    #todo: scrap with beautifulSoup using the url\n",
    "    #merge data into the temp dataframe\n",
    "    temp_df.nbr_faculty_members[i] = findNumberOf(soup,'total faculty')\n",
    "    temp_df.nbr_international_faculty_members[i] = findNumberOf(soup,'inter faculty')\n",
    "    temp_df.nbr_total_students[i] = findNumberOf(soup,'total student')\n",
    "    temp_df.nbr_international_total_students[i] = findNumberOf(soup,'total inter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all the informations we want into this DataFrame, we merge it with the initial one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the old dataframe with the new information\n",
    "#fullDataFrameTopUni200 contains all the information of the 200 top universities from www.topuniversities.com\n",
    "fullDataFrameTopUni200 = dfTopUni200.join(temp_df)\n",
    "fullDataFrameTopUni200.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.2. Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students?\n",
    "\n",
    "**Method**\n",
    "\n",
    "To answer this question we use the previous DataFrame filtering only the relevant parameters in column.\n",
    "Then we can compute the 2 ratios.\n",
    "\n",
    "Note that we drop 2 university that doesn't provide enough information on their personnal page.\n",
    "Indian Institute of Science (IISc) Bangalore doesn't have the number of international faculty member and New York University (NYU) doesn't have any data at all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function that compute the ratio of faculty member in function of students\n",
    "def percentFacAndStud (row):\n",
    "    return row['nbr_faculty_members']/row['nbr_total_students']\n",
    "#helper function that compute the ratio of international students in function of total students\n",
    "def percentInterAndStud (row):\n",
    "    return row['nbr_international_total_students']/row['nbr_total_students']\n",
    "\n",
    "\n",
    "#hard copy old DF and drop university that doesn't have the infromation required\n",
    "filteredDataFrame1 = fullDataFrameTopUni200.copy()[['title','nbr_faculty_members','nbr_international_faculty_members','nbr_total_students','nbr_international_total_students']].dropna()\n",
    "\n",
    "#create new row with the function percentFacAndStud to compute the ratio faculty member per student\n",
    "filteredDataFrame1['ratio_faculty_per_student'] = filteredDataFrame1.apply (lambda row: percentFacAndStud (row),axis=1)\n",
    "#create new row with the function percentInterAndStud to compute the ratio international students in function of total students\n",
    "filteredDataFrame1['ratio_international_students'] = filteredDataFrame1.apply (lambda row: percentInterAndStud (row),axis=1)\n",
    "\n",
    "#filter the result to answer question (a)\n",
    "resultDataFrame=filteredDataFrame1[['title','ratio_faculty_per_student','nbr_faculty_members','nbr_total_students']]\n",
    "#return the head of the dataframe, sorted by best ratio faculty per student\n",
    "topRatioFacPerStudent = resultDataFrame.sort_values(by='ratio_faculty_per_student',ascending=False).head(10)\n",
    "\n",
    "#plot them in a pie chart:\n",
    "topRatioFacPerStudent = topRatioFacPerStudent.set_index('title')['ratio_faculty_per_student']\n",
    "topRatioFacPerStudent.plot(kind='bar', title='Ratio of faculty member for 1 student')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 universities in term of **ratio between faculty members and students** are : \n",
    "* California Institute of Technology (Caltech)\n",
    "* Yale University\n",
    "* University of Oxford\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the result to answer question (b)\n",
    "resultDataFrame=filteredDataFrame1[['title','ratio_international_students','nbr_international_total_students','nbr_total_students']]\n",
    "#return the head of the dataframe, sorted by best ratio faculty per student\n",
    "topRatioInterStudents = resultDataFrame.sort_values(by='ratio_international_students',ascending=False).head(10)\n",
    "#plot them in a pie chart:\n",
    "topRatioInterStudents = topRatioInterStudents.set_index('title')['ratio_international_students']\n",
    "topRatioInterStudents.plot(kind='bar', title='Ratio of international students in function of total students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 universities in term of **ratio of international students** are:\n",
    "* London School of Economics and Political Science\n",
    "* **Ecole Polytechnique Fédérale de Lausanne (EPFL)**\t\n",
    "* Imperial College London"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3.c Answer the previous question aggregating the data by (c) country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter the full dataFrame to only releveant parameters\n",
    "filteredDataFrame1cd = fullDataFrameTopUni200.copy()[['country','region','nbr_faculty_members','nbr_international_faculty_members','nbr_total_students','nbr_international_total_students']]\n",
    "#aggregate the countries for question (c)\n",
    "countryDataFrame = filteredDataFrame1cd.drop('region',axis=1).groupby('country').agg('sum')\n",
    "\n",
    "#the same helper functions are applied to create the 2 ratio into 2 new columns\n",
    "countryDataFrame['ratio_faculty_per_student'] = countryDataFrame.apply (lambda row: percentFacAndStud (row),axis=1)\n",
    "countryDataFrame['ratio_international_students'] = countryDataFrame.apply (lambda row: percentInterAndStud (row),axis=1)\n",
    "\n",
    "topRatioFacPerStudent = countryDataFrame[['ratio_faculty_per_student','nbr_faculty_members','nbr_total_students']].sort_values(by='ratio_faculty_per_student',ascending=False).head(10)\n",
    "#plot them in a pie chart:\n",
    "topRatioFacPerStudent = topRatioFacPerStudent['ratio_faculty_per_student']\n",
    "topRatioFacPerStudent.plot(kind='bar', title='Ratio of faculty member for 1 student')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 countries in term of **ratio between faculty members and students** are:\n",
    "* Russia\n",
    "* Denmark\n",
    "* Saudia Arabia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topRatioInterStudents = countryDataFrame[['ratio_international_students','nbr_international_total_students','nbr_total_students']].sort_values(by='ratio_international_students',ascending=False).head(10)\n",
    "#plot them in a pie chart:\n",
    "topRatioInterStudents = topRatioInterStudents['ratio_international_students']\n",
    "topRatioInterStudents.plot(kind='bar', title='Ratio of international students in function of total students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 countries in term of **ratio of international students** are:\n",
    "* Australia\n",
    "* United Kingdom\t\n",
    "* Hong Kong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.3.d Answer the previous question aggregating the data by (d) region.\n",
    "\n",
    "<font color='MidnightBlue' size='3' face='cantarell'>\n",
    "\n",
    "<br> \n",
    "** Method **\n",
    "\n",
    "This code is similar to the code of question (c), but instead we aggregate on the label 'region' instead of 'country'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same code as for the country, but with region\n",
    "regionDataFrame = filteredDataFrame1cd.drop('country',axis=1).groupby('region').agg('sum')\n",
    "\n",
    "#the same helper functions are applied to create the 2 ratio into 2 new columns\n",
    "regionDataFrame['ratio_faculty_per_student'] = regionDataFrame.apply (lambda row: percentFacAndStud (row),axis=1)\n",
    "regionDataFrame['ratio_international_students'] = regionDataFrame.apply (lambda row: percentInterAndStud (row),axis=1)\n",
    "topRatioFacPerStudent = regionDataFrame[['ratio_faculty_per_student','nbr_faculty_members','nbr_total_students']].sort_values(by='ratio_faculty_per_student',ascending=False)\n",
    "#plot them in a pie chart:\n",
    "topRatioFacPerStudent = topRatioFacPerStudent['ratio_faculty_per_student']\n",
    "topRatioFacPerStudent.plot(kind='bar', title='Ratio of faculty member for 1 student')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 regions in term of **ratio between faculty members and students** are:\n",
    "* Asia\n",
    "* North America\n",
    "* Europe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topRatioInterStudents = regionDataFrame[['ratio_international_students','nbr_international_total_students','nbr_total_students']].sort_values(by='ratio_international_students',ascending=False)\n",
    "#plot them in a pie chart:\n",
    "topRatioInterStudents = topRatioInterStudents['ratio_international_students']\n",
    "topRatioInterStudents.plot(kind='bar', title='Ratio of international students in function of total students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 regions in term of **ratio of international students** are:\n",
    "* Oceania\n",
    "* Europe\n",
    "* North America"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Times Higer education"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1.1. Obtain the 200 top-ranking universities in www.timeshighereducation.com ([ranking 2018](http://timeshighereducation.com/world-university-rankings/2018/world-ranking)). Repeat the analysis of the previous point and discuss briefly what you observed.\n",
    "\n",
    "Again using the postman plugin on google chrome, we found the json representing the list of the universities:\n",
    "\n",
    "\n",
    "https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#json to dataframe using panda\n",
    "json_data2 = json.load(open('TimesRanking.json'))\n",
    "df2 = json_normalize(json_data2['data'])\n",
    "#print(df2.T.index)\n",
    "fullDataFrameTimes200 = df2.copy().head(200)\n",
    "#clean the data converting string into int\n",
    "fullDataFrameTimes200['stats_number_students'] = [int(x.replace(',','')) for x in fullDataFrameTimes200.stats_number_students]\n",
    "fullDataFrameTimes200['stats_student_staff_ratio'] = [1/float(x) for x in fullDataFrameTimes200.stats_student_staff_ratio]\n",
    "#change \"38%\" string into 0.38 int\n",
    "def stringPercentToInt(elem):\n",
    "    return float(elem.replace('%',''))/100\n",
    "fullDataFrameTimes200['stats_pc_intl_students'] = [stringPercentToInt(x) for x in fullDataFrameTimes200.stats_pc_intl_students]\n",
    "fullDataFrameTimes200.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Remark**\n",
    "\n",
    "\n",
    "Note that we changed **stats_student_staff_ratio** that represent the number of students for one faculty member to its inverse (1/stats_student_staff_ratio) : the number of **faculty member per student**. This way we have similar reference between this data frame and the one from TopUniversities.com.\n",
    "\n",
    "The 2 ratios needed for the analysis are already there and there is no more relevant information in specific page of each universities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredDataFrame2 = fullDataFrameTimes200.copy()[['name','location','rank','stats_pc_intl_students','stats_student_staff_ratio','stats_number_students']]\n",
    "#sort by ratio and rank too for tie\n",
    "topRatioFacPerStudent = filteredDataFrame2.sort_values(by=['stats_student_staff_ratio','rank'],ascending=[False,True]).head(10)\n",
    "#plot them in a pie chart:\n",
    "topRatioFacPerStudent = topRatioFacPerStudent.set_index('name')['stats_student_staff_ratio']\n",
    "topRatioFacPerStudent.plot(kind='bar', title='Ratio of faculty member for 1 student')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 universities in term of **ratio between faculty members and students** are:\n",
    "* Vanderbilt University\n",
    "* University of Copenhagen\n",
    "* Yale University"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort by ratio and rank too for tie\n",
    "topRatioInterStudents = filteredDataFrame2.sort_values(by=['stats_pc_intl_students','rank'],ascending=[False,True]).head(10)\n",
    "#plot them in a pie chart:\n",
    "topRatioInterStudents = topRatioInterStudents.set_index('name')['stats_pc_intl_students']\n",
    "topRatioInterStudents.plot(kind='bar', title='Ratio of international students in function of total students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 universities in term of **ratio of international students** are:\n",
    "* London School of Economics and Political Science\n",
    "* University of Luxembourg\t\n",
    "* Imperial College London\n",
    "\n",
    "In contrast with the first dataFrame, we only have the country to agreggate in this case. The problem is that we can't easily aggregate, because we can't just sum the percentage. So we will subtract the number of international student and the number of staff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B.1.2.c Answer the previous question [1] aggregating the data by (c) country.\n",
    "[1] Which are the best universities in term of: (a) ratio between faculty members and students, (b) ratio of international students ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function that compute the number of international students\n",
    "def computeNbrInternationalStudent(row):\n",
    "    #we floor because the percentage are approximated and floored.\n",
    "    return int(np.floor(row['stats_pc_intl_students']*row['stats_number_students']))\n",
    "\n",
    "#helper function that compute the number of staff member\n",
    "def computeNbrStaffs(row):\n",
    "    #we floor because the percentage are approximated and floored.\n",
    "    return int(np.floor(row['stats_student_staff_ratio']*row['stats_number_students']))\n",
    "\n",
    "#filter the full dataFrame to only releveant parameters \n",
    "fullDataFrameTimes200['stats_number_international_students'] = fullDataFrameTimes200.apply (lambda row: computeNbrInternationalStudent (row),axis=1)\n",
    "fullDataFrameTimes200['stats_number_staffs'] = fullDataFrameTimes200.apply (lambda row: computeNbrStaffs (row),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we created 2 columns in the real data frame, maybe thoses data are useful for later. Now we can compute by aggregating like in exercice 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function that compute the ratio of faculty member in function of students\n",
    "def percentFacAndStud2 (row):\n",
    "    return row['stats_number_staffs']/row['stats_number_students']\n",
    "#helper function that compute the ratio of international students in function of total students\n",
    "def percentInterAndStud2 (row):\n",
    "    return row['stats_number_international_students']/row['stats_number_students']\n",
    "#aggregate the countries for question (c)\n",
    "countryDataFrame2 = fullDataFrameTimes200.copy()[['location','stats_number_international_students','stats_number_staffs','stats_number_students']]\n",
    "countryDataFrame2 = countryDataFrame2.groupby('location').agg('sum')\n",
    "#we use the helper functions to create the 2 ratio into 2 new columns\n",
    "countryDataFrame2['ratio_faculty_per_student'] = countryDataFrame2.apply (lambda row: percentFacAndStud2 (row),axis=1)\n",
    "countryDataFrame2['ratio_international_students'] = countryDataFrame2.apply (lambda row: percentInterAndStud2 (row),axis=1)\n",
    "topRatioFacPerStudent = countryDataFrame2[['ratio_faculty_per_student','stats_number_staffs','stats_number_students']].sort_values(by='ratio_faculty_per_student',ascending=False).head(10)\n",
    "#plot them in a pie chart:\n",
    "topRatioFacPerStudent = topRatioFacPerStudent['ratio_faculty_per_student']\n",
    "topRatioFacPerStudent.plot(kind='bar', title='Ratio of faculty member for 1 student')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 country in term of **ratio between faculty members and students** are:\n",
    "* Denmark\n",
    "* Russia\n",
    "* Japan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topRatioInterStudents = countryDataFrame2[['ratio_international_students']].sort_values(by='ratio_international_students',ascending=False).head(10)\n",
    "#plot them in a pie chart:\n",
    "topRatioInterStudents.plot(kind='bar', title='Ratio of international students in function of total students')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Result **\n",
    "\n",
    "The top 3 country in term of **ratio of international students** are:\n",
    "* Luxembourg\n",
    "* United Kingdom\n",
    "* Hong Kong\n",
    "\n",
    "\n",
    "** Remark **\n",
    "\n",
    "We notice that some results are different between the data of the 2 sites. There is 2 reasons for that:\n",
    "* Some universities are not in both data sets, but still have a reallly good ratio. For example the University of Luxembourg (rank 179 and 2nd in ratio of international students) in the seconds site, but is inexistant in TimesUniversities.com.\n",
    "\n",
    "* There is a difference between the 2 data frames in parameters that should be equivalent.\n",
    "See next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data of the site TopUni\n",
    "data1 = fullDataFrameTopUni200.set_index('title').loc[['Imperial College London','Ecole Polytechnique Fédérale de Lausanne (EPFL)'],['nbr_total_students','nbr_international_total_students']]\n",
    "print(\"data of the site TopUni:\")\n",
    "print(data1.to_string())\n",
    "#data of the site Times\n",
    "data2 = fullDataFrameTimes200.set_index('name').loc[['Imperial College London','École Polytechnique Fédérale de Lausanne'],['stats_number_students','stats_number_international_students']]\n",
    "print(\"-\"*100)\n",
    "print(\"data of the site Times:\")\n",
    "print(data2.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Remark **\n",
    "\n",
    "Parameters that we think wont vary between the data set (number of students, number of international students,... ) are actually different. It's why the analyse of the 2 ratios between the two sites **return different results** in _Ex.1_ and _Ex.2_. This is maybe due to different standards for counting or to different data update dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now for the region:\n",
    "We will use the first dataframe that has links between country and region to add a new region column in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapCountryRegion = fullDataFrameTopUni200.copy()[['region','country']].drop_duplicates(subset=['region', 'country'], keep='first')\n",
    "mapCountryRegion = mapCountryRegion.set_index('country')\n",
    "\n",
    "def createRegionUsingCountry(row):\n",
    "    #we floor because the percentage are approximated and floored.\n",
    "    return mapCountryRegion.region.get(row['location'], np.nan)\n",
    "\n",
    "filteredDataFrame3 = fullDataFrameTimes200.copy()[['name','location']]\n",
    "filteredDataFrame3['region'] = filteredDataFrame3.apply (lambda row: createRegionUsingCountry (row),axis=1)\n",
    "#there is only 2 countries that are not in the first dataframe: russian federation and luxembourg, so we can add them by hand\n",
    "#na_free = filteredDataFrame3.dropna()\n",
    "#only_na = filteredDataFrame3[~filteredDataFrame3.index.isin(na_free.index)]\n",
    "#only_na represent the list of country that have no regions\n",
    "#only_na\n",
    "#Russia\n",
    "filteredDataFrame3 = filteredDataFrame3.set_index('name')\n",
    "filteredDataFrame3.set_value('Lomonosov Moscow State University','region','Europe')\n",
    "filteredDataFrame3.set_value('University of Luxembourg','region','Europe')\n",
    "#filteredDataFrame3.set_value('Massachusetts Institute of Technology (MIT)','region','United States')\n",
    "\n",
    "def mapCountry(title):\n",
    "    return filteredDataFrame3.loc[title].region\n",
    "\n",
    "filteredDataFrame3.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our index to generate the wanted column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullDataFrameTimes200['region'] = fullDataFrameTimes200['name'].apply(mapCountry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can do our plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullDataFrameTimes200[['region', \"name\"]].groupby('region').count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. merge datasets\n",
    "Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Method**\n",
    "We have to merge data based on names which may slightly differ : different language, missing small linking words, re-ordered words... We need something to match the two list of names correctly.  \n",
    "\n",
    "Our strategy here will be to build a UID (based on the country + name/title of the university). We improved iteratively our uid-generating function while back checking the set of \"non-matching names/titles\" at each iteration.  \n",
    "\n",
    "\n",
    "it features : \n",
    "- case + accent + punctuation insensitivity\n",
    "- short words removal / long words truncating / words sorting, meant to avoid the translation step for most words\n",
    "- duplicated words removal\n",
    "- some manual translation for some difficult words in the dataset\n",
    "\n",
    "\n",
    "And here are the results at each iteration :  \n",
    "- lower + accents             : 66 rows dropped in each dataset   \n",
    "- . += short words removal    : 59        -----------   \n",
    "- . += truncate words         : 55          -------------- all this helps to create a make-do translation  \n",
    "- . += sort words             : 54           ----------------------          \n",
    "- . += remove duplicate words : 53  \n",
    "- . += impr. punctuation rem. : 51  \n",
    "- . += manual translations    : 49\n",
    "\n",
    "\n",
    "Important as well : our goal after that is to find correlations between the values of this dataset. We will actually find these correlations on values across datasets (i.e, corr(values_from_times, values_from_topUni). Therefore, it makes sense to keep only universities that exist in both rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing equality symbol that is sometines in from of 'rank'\n",
    "def correct_rank (obj):\n",
    "    return int(obj.replace('=',''))\n",
    "\n",
    "\n",
    "cleared_TopUni200 = fullDataFrameTopUni200.copy()\n",
    "# we will use the ratios we computed previously later on\n",
    "cleared_TopUni200['ratio_international_students'] = filteredDataFrame1['ratio_international_students']\n",
    "cleared_TopUni200['ratio_faculty_per_student'] = filteredDataFrame1['ratio_faculty_per_student']\n",
    "# now we clear the title and rank in terms of undesired signs and symbols\n",
    "cleared_TopUni200['rank'] = [correct_rank(k) for k in cleared_TopUni200['rank_display']]\n",
    "final_TopUni200 = cleared_TopUni200.drop('rank_display',1)\n",
    "final_TopUni200 = final_TopUni200.rename(columns = {'score':'score_topUni'})\n",
    "\n",
    "final_TopUni200.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_Times = fullDataFrameTimes200.copy()\n",
    "\n",
    "# clear names and ranks\n",
    "cleared_Times['rank'] = [correct_rank(k) for k in cleared_Times['rank']]\n",
    "# rename interesting statistics to facilitate comparision between websites\n",
    "final_Times = cleared_Times.rename(columns = {'stats_number_students':'nbr_total_students',\n",
    "                                                'stats_number_international_students':'nbr_international_total_students',\n",
    "                                                'stats_number_staffs':'nbr_faculty_members',\n",
    "                                                'stats_pc_intl_students':'ratio_international_students',\n",
    "                                                'stats_student_staff_ratio':'ratio_faculty_per_student',\n",
    "                                                'location':'country',\n",
    "                                                'name':'title',\n",
    "                                                'scores_overall':'score_times'})\n",
    "\n",
    "# Fix wonky ex-aequos in Times\n",
    "def asFloat(serie) : return serie.apply(lambda e : float(e))\n",
    "def fix_times_rank(row) : \n",
    "    return (asFloat(row['rank_order'])//10).apply(lambda e : int(e))\n",
    "final_Times['rank'] = fix_times_rank(final_Times)\n",
    "final_Times.drop('rank_order', axis=1, inplace=True)\n",
    "\n",
    "final_Times.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, here are helpers for the uid generator, followed by the generator itself. It's basically doing a long sequence of simple steps to create a uid.  \n",
    "This UID is pretty good : We did two checks on the dataset :\n",
    "- the number of rows merged together, and the number of rows that we know are being dropped actually sum up to 200, which means there are no \"false negative\" merges. E.g. 'ecole de commerce' and 'ecole de commerage' being incorrectly merged under the uid 'ecol_comm'.  \n",
    "- we can look at the rejected data (rows that didn't find a match) and see that for the most part (all but ~2), they actually don't have a match. \n",
    "\n",
    "You will find these two checks implemented 3 and 4 cells forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper : removes acronyms e.g (EPFL) at the end of Ecole Polytechnique Federale de Lausanne\n",
    "def remove_acronyms (obj):\n",
    "    # we first look for a sigle in the object (title)\n",
    "    k = obj.find('(')-1\n",
    "    if k > 0:\n",
    "        return obj[0:k] #if there is a sigle we take the object until this symbol\n",
    "    return obj\n",
    "\n",
    "# Helper : removes accents (most common ones)\n",
    "def remove_punctuation (obj):\n",
    "    return (obj.replace('é','e').replace('è','e').replace('ó','o')\n",
    "                .replace('ü','u').replace('ä','a').replace('&','')\n",
    "                .replace('-',' ').replace('_',' ').replace(',', ' ')\n",
    "                .replace('.',' ').replace(';',' ').replace('ò', 'o')\n",
    "           )\n",
    "\n",
    "# Helper : manual translation for some problematic words\n",
    "def translate(word) : \n",
    "    return {\n",
    "        'freie' : 'free',\n",
    "        'vrije' : 'free',\n",
    "        'libre' : 'free',\n",
    "        'brussel' : 'bruxelles',\n",
    "        'ida' : 'nahui'\n",
    "    }.get(word, word) # default : return 'word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create UID based on university name. This UID aims to ignore : \n",
    "    - capitalization / accents\n",
    "    - short, insignificant words (i.e : 'The london Uni' and 'London Uni' should yield the same UID)\n",
    "    - language (i.e : Université de londre and London university)\n",
    "    - words ordering (cf above)\n",
    "\"\"\"\n",
    "def create_uid(row) : \n",
    "    low = remove_punctuation(remove_acronyms(row['title'].lower()))\n",
    "    split = low.split(' ')\n",
    "    dedup = list(set(split))\n",
    "    filtered = [s for s in dedup if(len(s)>3 or s.lower()=='new')]      # remove 'and', 'the', 'le', ...\n",
    "    if(len(filtered)<=1) :                         # Avoid collisions if there are not enough long words\n",
    "        filtered = dedup\n",
    "    translated = [translate(w) for w in filtered]\n",
    "    translated.sort()\n",
    "    concat = \"_\".join([s[:6] for s in translated])   # makeshift for translation : e.g universidad, universitaet, university...\n",
    "    #print(\"concat : \", concat)\n",
    "    return row['country']+concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge using our UIDs as index\n",
    "final_TopUni200['uid']=final_TopUni200.apply(create_uid, axis=1)\n",
    "final_Times['uid']=final_Times.apply(create_uid, axis=1)\n",
    "merged_data = final_Times.merge(final_TopUni200,how = 'inner',suffixes=('_times', '_topUni'), on='uid')\n",
    "\n",
    "print(\"number of accepted rows : \",merged_data.shape[0])\n",
    "merged_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of dropped row, and verify manually that they are indeed not matching\n",
    "times_dropped = final_Times[['country', 'title', 'uid']][~final_Times.uid.isin(final_TopUni200.uid.values)]#.sort_values('country')\n",
    "topuni_dropped = final_TopUni200[['country', 'title', 'uid']][~final_TopUni200.uid.isin(final_Times.uid.values)]#.sort_values('country')\n",
    "res = topuni_dropped.merge(times_dropped,how = 'outer',suffixes=('_topUni', '_times'), on=['country','uid'])\n",
    "\n",
    "idx = 0  # print out rows [idx, idx+30]\n",
    "print(\"Number of rejected rows : \",len(res.sort_values('country'))/2.0)\n",
    "res.sort_values('country').head(30+idx).tail(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that data has been merged, we have duplicated columns (country, title, name, alias, ...) that we need to get rid of.\n",
    "\n",
    "At the end of this cell, there's still a mess of columns, which we will sort out in the next part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the end we want to remove duplicates, like countries\n",
    "# supposing that the location is obviously the same even if the formulation may differ\n",
    "merged_data.drop(['country_times','title_times'], axis=1, inplace=True)\n",
    "merged_data.rename(columns={'country_topUni':'country', 'title_topUni':'title'}, inplace=True)\n",
    "merged_data.set_index(['country','title'])\n",
    "merged_data.columns\n",
    "\n",
    "merged_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Do correlation?\n",
    "\n",
    "Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?\n",
    "\n",
    "** Method** \n",
    "\n",
    "First, let's examine both ranking's data to find out what could be interresting to correlate. NB : By correlation, we mean \"cross-correlation\". It's self explanatory here and doesn't induce confusion, so we'll use the shorter \"correlation\" term later on.\n",
    "\n",
    "It would be interesting to find out how some values correlate : \n",
    "- the ratio of international students with scores_international_outlook\n",
    "- the ratio of faculty member per student with scores_teaching\n",
    "- the number of faculty members with research_score\n",
    "\n",
    "As a \"Control experiment\", we will also look at the correlation :\n",
    "- the number of subjects offered and the score_industry_income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_TopUni200.columns)\n",
    "print(final_Times.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='MidnightBlue'> We will cleanly merge the data of both rankings before we proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns we will keep to produce stats on\n",
    "stats_cols = [  # Fields that exist in both rankings -> will be merged\n",
    "                'title',\n",
    "                'nid_topUni', 'nid_times',\n",
    "                'rank_topUni', 'rank_times', \n",
    "                'nbr_total_students_topUni', 'nbr_total_students_times',\n",
    "                'ratio_international_students_topUni', 'ratio_international_students_times', \n",
    "                'ratio_faculty_per_student_topUni', 'ratio_faculty_per_student_times',\n",
    "                'nbr_faculty_members_times', 'nbr_faculty_members_topUni', \n",
    "                # Fields that exist in only one ranking\n",
    "                # Since we merge both rankings, we can correlate values across rankings !\n",
    "                'scores_international_outlook',\n",
    "                'scores_teaching',\n",
    "                'scores_research',\n",
    "                'scores_industry_income',\n",
    "                'subjects_offered',\n",
    "                'score_times',\n",
    "                'score_topUni'\n",
    "                ]\n",
    "\n",
    "# filter and copy the dataset\n",
    "stats_data = merged_data[stats_cols].copy()\n",
    "\n",
    "# Merge similar columns by averaging their values\n",
    "def asFloat(serie) : return serie.apply(lambda e : float(e))\n",
    "def avg_cols(dataframe, col1, col2, newColName) :\n",
    "    # replace col1\n",
    "    dataframe[col1] = (asFloat(dataframe[col1]) + asFloat(dataframe[col2]))/2.0\n",
    "    dataframe.rename(columns={col1:newColName}, inplace=True)\n",
    "    # drop col2\n",
    "    dataframe.drop(col2, axis=1, inplace=True)  \n",
    "    \n",
    "# Process the data as necessary    \n",
    "avg_cols(stats_data, 'nbr_total_students_topUni', 'nbr_total_students_times', 'nbr_total_students')   \n",
    "avg_cols(stats_data, 'ratio_international_students_topUni', 'ratio_international_students_times', 'ratio_international_students')    \n",
    "avg_cols(stats_data, 'ratio_faculty_per_student_topUni', 'ratio_faculty_per_student_times', 'ratio_faculty_per_student')    \n",
    "avg_cols(stats_data, 'nbr_faculty_members_times', 'nbr_faculty_members_topUni', 'nbr_faculty_members')   \n",
    "\n",
    "def count_subjects(subjects) : \n",
    "    return len(subjects.split(','))\n",
    "stats_data['subjects_offered'] = stats_data['subjects_offered'].apply(count_subjects)\n",
    "\n",
    "\n",
    "stats_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the \"statistics\" correlation. To be precise, we search the cross-correlation coefficient of the two series : https://en.wikipedia.org/wiki/Cross-correlation#Time_series_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a wrapper, for clean code\n",
    "def correlate(col1, col2, dataframe=stats_data, silent=False) : \n",
    "    vals1 = asFloat(dataframe[col1].fillna(0))\n",
    "    vals2 = asFloat(dataframe[col2].fillna(0))\n",
    "    mean1 = np.mean(vals1)\n",
    "    mean2 = np.mean(vals2)\n",
    "    std1 = np.std(vals1)\n",
    "    std2 = np.std(vals2)\n",
    "    crossCorr = (1/len(vals1))*np.sum(((vals1-mean2)*(vals2-mean2)))*(1/(std1*std2))\n",
    "    \n",
    "    if(not silent) : print(\"\\nThe correlation between\",col1, \"and\", col2, \"is\", crossCorr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stats_data[['ratio_international_students', 'scores_international_outlook']].head(3))\n",
    "correlate('ratio_international_students', 'scores_international_outlook')    \n",
    "correlate('ratio_faculty_per_student', 'scores_teaching')\n",
    "correlate('nbr_faculty_members', 'scores_research')\n",
    "\n",
    "correlate('subjects_offered', 'scores_industry_income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "The cross-correlation coefficient is a scalar number that lies within [-1, 1], 1 indicating that the two series change values similarily, 0, that there is no similarity in how their values change, and -1 that their values change in an opposite manner.\n",
    "\n",
    "We expected the ratio of international students and the international outlook score to have a high correlation coefficient, and they do.  \n",
    "Similarily, the number of faculty member per student is quite correlated with the teaching scores.   \n",
    "Surprisingly, the number of faculty members, people that should be conducting researchs, is quite weakly correlated with the research score. \n",
    "\n",
    "\n",
    "Finally, our \"control experiment\" shows that there is no strong correlation between the number of subjects teached, and the industry income of a university."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Best university? (not EPFL)\n",
    "\n",
    "Can you find the best university taking in consideration both rankings? Explain your approach.\n",
    "\n",
    "We will re-use data from #4, as it contains all the important informations\n",
    "\n",
    "To find the best university, there are come important considerations that will help us create a ranking algorithm from the data we have : \n",
    "- We prefer to use the score instead of the rank, because it gives more information on how a rankings classifies them : you know how much of a gap there is between two universities. Since both rankings provide an overall score, we can use that\n",
    "\n",
    "- What credit can we give to each dataset ? We have no particular reason to trust one of the two more that the other. Therefore, it makes no sense to give different weigths to any of the two.   \n",
    "=> Therefore, the main feature we care about is how coherent the two datasets are among themselves. Starting from here, there are multiple way we can decide how we will balance coherence versus \"best performance in one of the two datasets\n",
    "\n",
    "- What metrics are important ? Obviously, the mean value represents the 'average opinion of the two rankings'. Additionally, we decided to factor in the distance between the two ranks (=\"how much do rankings agree about a given university\"), divided by the mean value, to express that a fixed distance should matter differently depending on how well a university scores : a 5-ranks difference is much more significant when you're in the top 10 universities than when you're in the worst 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are useful metrics we obtained throughout our testing\n",
    "rank_range = 200\n",
    "max_dist = 127\n",
    "ranks_std = np.std(stats_data['rank_times'])\n",
    "dist_list = np.abs(stats_data['rank_times'] - stats_data['rank_topUni'])\n",
    "dist_mean = np.mean(dist_list)\n",
    "dist_std = np.std(dist_list)\n",
    "\n",
    "\n",
    "def tot_rank(row) :\n",
    "    # Some useful values describing the data\n",
    "    s1 = float(row['score_topUni'])\n",
    "    s2 = float(row['score_times'])\n",
    "    r1 = float(row['rank_topUni'])\n",
    "    r2 = float(row['rank_times']) \n",
    "    dist = np.abs(r1-r2)\n",
    "    mean = (s1 + s2)/2.0\n",
    "    mean_dist = mean - (dist/mean)\n",
    "    return mean_dist    \n",
    "\n",
    "    \n",
    "stats_data['tot_score'] = stats_data.apply(tot_rank, axis=1)\n",
    "stats_data.sort_values('tot_score', inplace=True, ascending=False)\n",
    "stats_data[['title', 'tot_score', 'score_topUni', 'score_times', 'rank_topUni', 'rank_times']].head(12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " With these parameters, described as above, the MIT comes out on top, but we should notice that the first three universities (MIT, Stanford, Caltech) are very close to one another. \n",
    "One thing to notice is that our model, while it takes into account the rank distance, favors universities that have good mean score. In other models where the rank distance is penalized more heavily, Stanford often comes out on top.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
